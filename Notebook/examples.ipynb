{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a POC project in parts.\n",
    "\n",
    "1. Create a docker-compose application that will have all applications\n",
    "2. Create a OpenWheather API\n",
    "3. Create a DDL for Clickhouse based on Schema\n",
    "4. Create a view from pandas transformations\n",
    "5. Final touch to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1: Create Infrastructure\n",
    "You are a Data Engineer. Create a docker-compose application that will contain \n",
    "clickhouse and graphana. Clickhouse ports should be exposed so that will be accesible \n",
    "from outside of container. Respond only with content of `docker-compose.yaml`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "version: '3'\n",
    "\n",
    "services:\n",
    "  clickhouse-server:\n",
    "    image: yandex/clickhouse-server\n",
    "    ports:\n",
    "      - \"8123:8123\" # HTTP interface\n",
    "      - \"9000:9000\" # Native client interface\n",
    "      - \"9009:9009\" # GRPC interface (optional)\n",
    "    ulimits:\n",
    "      nofile:\n",
    "        soft: 262144\n",
    "        hard: 262144\n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    depends_on:\n",
    "      - clickhouse-server\n",
    "    environment:\n",
    "      - GF_SECURITY_ADMIN_PASSWORD=admin # Define your own password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2: Create API Clinet\n",
    "You are Data Engineer. Create a production ready script that will use OpenWheather API to fetch hourly wheather forecast in \n",
    "Poznań, Poland and save it as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "CITY = 'Poznań'\n",
    "COUNTRY_CODE = 'PL'\n",
    "BASE_URL = 'http://api.openweathermap.org/data/2.5/forecast'\n",
    "CSV_FILE_PATH = 'poznan_hourly_weather_forecast.csv'\n",
    "\n",
    "def get_weather_data(api_key, city, country_code):\n",
    "    # Construct the API query url\n",
    "    url = f\"{BASE_URL}?q={city},{country_code}&appid={api_key}&units=metric\"\n",
    "    \n",
    "    # Make a GET request to the OpenWeatherMap API\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error fetching data from OpenWeather API: Status Code {response.status_code}\")\n",
    "\n",
    "def process_weather_data(weather_data):\n",
    "    # Parse the hourly data\n",
    "    hourly_data = weather_data['list']\n",
    "    \n",
    "    # Create a list to hold our parsed data\n",
    "    weather_rows = []\n",
    "    for entry in hourly_data:\n",
    "        weather_details = {\n",
    "            'datetime': datetime.fromtimestamp(entry['dt']),\n",
    "            'temperature': entry['main']['temp'],\n",
    "            'feels_like': entry['main']['feels_like'],\n",
    "            'pressure': entry['main']['pressure'],\n",
    "            'humidity': entry['main']['humidity'],\n",
    "            'wind_speed': entry['wind']['speed'],\n",
    "            'description': entry['weather'][0]['description']\n",
    "        }\n",
    "        weather_rows.append(weather_details)\n",
    "        \n",
    "    # Convert the list into a pandas DataFrame\n",
    "    return pd.DataFrame(weather_rows)\n",
    "\n",
    "def save_data_to_csv(data, file_path):\n",
    "    # Ensure the folder where you want to save the file exists or handle exceptions as needed.\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Fetch the weather data from OpenWeather API\n",
    "        weather_data = get_weather_data(API_KEY, CITY, COUNTRY_CODE)\n",
    "        \n",
    "        # Process the weather data into a suitable format\n",
    "        processed_data = process_weather_data(weather_data)\n",
    "        \n",
    "        # Save the processed data to CSV\n",
    "        save_data_to_csv(processed_data, CSV_FILE_PATH)\n",
    "        \n",
    "        print(\"Hourly weather forecast retrieval complete.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3:\n",
    "Create `CREATE TABLE` DDL for Clickhouse from this polars schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"poznan_hourly_weather_forecast.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 4:\n",
    "Write a pandas transformation that will group by day and calculate min, max and avg temp for each day from csv liek this. use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>avg_temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>8.62</td>\n",
       "      <td>15.31</td>\n",
       "      <td>11.802000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-08</th>\n",
       "      <td>5.07</td>\n",
       "      <td>15.91</td>\n",
       "      <td>10.903750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09</th>\n",
       "      <td>6.02</td>\n",
       "      <td>18.57</td>\n",
       "      <td>13.161250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10</th>\n",
       "      <td>10.78</td>\n",
       "      <td>16.75</td>\n",
       "      <td>13.336250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-11</th>\n",
       "      <td>11.22</td>\n",
       "      <td>14.09</td>\n",
       "      <td>12.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-12</th>\n",
       "      <td>5.23</td>\n",
       "      <td>9.59</td>\n",
       "      <td>7.746667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            min_temperature  max_temperature  avg_temperature\n",
       "datetime                                                     \n",
       "2024-05-07             8.62            15.31        11.802000\n",
       "2024-05-08             5.07            15.91        10.903750\n",
       "2024-05-09             6.02            18.57        13.161250\n",
       "2024-05-10            10.78            16.75        13.336250\n",
       "2024-05-11            11.22            14.09        12.285000\n",
       "2024-05-12             5.23             9.59         7.746667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_csv(\"poznan_hourly_weather_forecast.csv\", parse_dates=True)\n",
    "\n",
    "# Convert 'datetime' column to datetime objects\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Set the 'datetime' column as the DataFrame's index\n",
    "df.set_index('datetime', inplace=True)\n",
    "\n",
    "# Group the data by day, and calculate min, max, and average temperature\n",
    "daily_stats = df.groupby(pd.Grouper(freq='D')).agg(\n",
    "    min_temperature=('temperature', 'min'),\n",
    "    max_temperature=('temperature', 'max'),\n",
    "    avg_temperature=('temperature', 'mean')\n",
    ")\n",
    "\n",
    "daily_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 5:\n",
    "Translate provided pandas transformation to SQL (Clickhouse style) and create a DDL that will create a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE VIEW daily_weather_stats AS\n",
    "SELECT\n",
    "    toDate(datetime) as day, -- This casts the datetime to a date, effectively grouping by day\n",
    "    min(temperature) AS min_temperature,\n",
    "    max(temperature) AS max_temperature,\n",
    "    avg(temperature) AS avg_temperature\n",
    "FROM\n",
    "    poznan_hourly_weather_forecast\n",
    "GROUP BY\n",
    "    day;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Prezentacji!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import Union, Dict\n",
    "\n",
    "def to_dict(input_data: Union[Dict, 'DataclassType']) -> Dict:\n",
    "    if isinstance(input_data, dict):\n",
    "        return input_data\n",
    "    elif hasattr(input_data, '__dataclass_fields__'):  # Checks if input_data is a dataclass\n",
    "        return asdict(input_data)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a dictionary or a dataclass instance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the S3 file URI:\n",
    "`s3://paida_bucket/presentations/year=2024/month=05/day=05/paida_analytics_20240505190000.csv`\n",
    "\n",
    "Write a regex pattern that will extract:\n",
    "collection = \"presentations\"\n",
    "partition = \"2024-05-05\"\n",
    "table_namne = \"paida_analytics\"\n",
    "created_at = \"2024-05-05 19:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "    pattern = r's3://([^/]+)/([^/]+)/year=(\\d{4})/month=(\\d{2})/day=(\\d{2})/([^_]+)_(\\d{14})\\.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Generate a sample dataset in csv that will meets following constaints:\n",
    "- Columns: Id int, first_name str, last_name str, age int, birthday date, created_at datetime\n",
    "- Names should be Polish\n",
    "- Age should be between 18 and 50\n",
    "- All users should have bithday at may 22th.ABORT\n",
    "\n",
    "Respond only with markdown codeblock and nothing else.\n",
    "    \n",
    "Wygeneruj przykładowy zestaw danych w formacie csv, który będzie spełniał następujące warunki:\n",
    "- Kolumny: id int, first_name str, last_name str, age int, birthday date, created_at datetime\n",
    "- Imiona i nazwiska powinny być polskie\n",
    "- Wiek powinien być pomiędzy 18 a 50\n",
    "- Wszyscy użytkownicy powinni mieć urodziny 22 maja.\n",
    "    \n",
    "\n",
    "This is a transformation in pandas. Translate this transformation to polars.\n",
    "\n",
    "\n",
    "agg_df = df.groupby('product').agg({\n",
    "    'sales': 'sum',\n",
    "    'price': 'mean'\n",
    "}).reset_index()\n",
    "filtered_df = df[df['price'] > 9.99]\n",
    "df['rolling_mean_sales'] = df['sales'].rolling(window=3).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"product\").agg({\"sales\": \"sum\", \"price\": \"mean\"}).reset_index()\n",
    "df = df[df[\"price\"] > 9.99]\n",
    "df[\"rolling_mean_sales\"] = df[\"sales\"].rolling(window=3).mean()\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "df = (\n",
    "    df.groupby(\"date\")\n",
    "    .agg([pl.sum(\"sales\").alias(\"sales\"), pl.mean(\"price\").alias(\"price\")])\n",
    "    .filter(pl.col(\"price\") > 9.99)\n",
    "    .with_column(\n",
    "        pl.col(\"sales\").rolling_mean(window_size=7).alias(\"rolling_mean_sales\")\n",
    "    )\n",
    ")\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Union, Dict\n",
    "\n",
    "\n",
    "def to_dict(input_data: Union[Dict, \"DataclassType\"]) -> Dict:\n",
    "    if isinstance(input_data, dict):\n",
    "        return input_data\n",
    "    elif hasattr(input_data, \"__dataclass_fields__\"):\n",
    "        return asdict(input_data)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a dictionary or a dataclass instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Id': Int64, 'first_name': String, 'last_name': String, 'age': Int64, 'birthday': String, 'created_at': String}\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "data = io.BytesIO(b\"\"\"Id,first_name,last_name,age,birthday,created_at\n",
    "1,Kacper,Nowak,24,1999-05-22,2023-04-01T14:23:55\n",
    "2,Aleksandra,Kowalska,31,1992-05-22,2023-04-02T10:45:30\n",
    "3,Jan,Kaminski,28,1995-05-22,2023-04-01T18:00:12\n",
    "4,Marta,Wisniewska,35,1988-05-22,2023-04-01T20:15:45\n",
    "5,Piotr,Wojcik,42,1981-05-22,2023-04-03T09:22:37\n",
    "6,Julia,Zajac,21,2002-05-22,2023-04-02T12:48:56\n",
    "7,Tomasz,Kozlowski,38,1985-05-22,2023-04-02T16:33:11\n",
    "8,Anna,Pawlak,29,1994-05-22,2023-04-01T17:05:42\n",
    "9,Marcin,Dabrowski,44,1979-05-22,2023-04-02T07:02:00\n",
    "10,Katarzyna,Lewandowska,19,2004-05-22,2023-04-03T15:40:29\"\"\")\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "print(dict(pl.read_csv(data).schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (389514943.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Generate a CREATE TABLE DDL SQL statement for MSSQL Database that will create a table compatible with this polars schema\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Generate a CREATE TABLE DDL SQL statement for MSSQL Database that will create a table compatible with this polars schema\n",
    "```{'Id': Int64, 'first_name': String, 'last_name': String, 'age': Int64, 'birthday': String, 'created_at': String}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "{'Id': Int64, 'first_name': String, 'last_name': String, 'age': Int64, 'birthday': String, 'created_at': String}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE MyTable (\n",
    "    Id INT NOT NULL,\n",
    "    first_name NVARCHAR(MAX),\n",
    "    last_name NVARCHAR(MAX),\n",
    "    age INT,\n",
    "    birthday NVARCHAR(MAX),\n",
    "    created_at NVARCHAR(MAX)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(environment: str, credentials: Credentials) -> Dict[str, Any]:\n",
    "    with open(CONFIG_PATH[environment]) as f:\n",
    "        template = Template(f.read())\n",
    "        template.globals[\"secret\"] = partial(get_secret, credentials=credentials)\n",
    "        template.globals[\"masked_secret\"] = get_masked_secret\n",
    "        render = template.render()\n",
    "        config = yaml.safe_load(render)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_config(environment: str, credentials: Credentials) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the configuration file based on the specified environment.\n",
    "\n",
    "    This function reads the configuration file for the given environment and\n",
    "    generates dynamic variables using Jinja2 templates. Any secrets required \n",
    "    in the configuration template are fetched dynamically using the provided \n",
    "    credentials.\n",
    "\n",
    "    Args:\n",
    "        environment (str): The name of the environment for which the \n",
    "            configuration file needs to be loaded.\n",
    "        credentials (Credentials): The credentials object required to fetch\n",
    "            any secrets needed in the configuration from a secure storage.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the loaded configuration.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the configuration file for the provided \n",
    "            environment doesn't exist.\n",
    "        yaml.YAMLError: If there is an error parsing the configuration file.\n",
    "    \"\"\"\n",
    "    with open(CONFIG_PATH[environment]) as f:\n",
    "        template = Template(f.read())\n",
    "        template.globals[\"secret\"] = partial(get_secret, credentials=credentials)\n",
    "        template.globals[\"masked_secret\"] = get_masked_secret\n",
    "        render = template.render()\n",
    "        config = yaml.safe_load(render)\n",
    "\n",
    "    return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
